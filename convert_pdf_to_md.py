import os
import sys
from pathlib import Path
from pdf_craft import create_pdf_page_extractor, MarkDownWriter, ExtractedTableFormat, LLM, analyse, CorrectionMode
import time
import re
import multiprocessing as mp
from concurrent.futures import ProcessPoolExecutor, as_completed
import threading

def setup_llm(llm_type="none"):
    """è¨­å®š LLM é…ç½®"""
    if llm_type == "ollama":
        # æœ¬åœ° Ollama é…ç½®
        llm = LLM(
            key="",  # Ollama ä¸éœ€è¦ key
            url="http://localhost:11434",  # Ollama é è¨­ç«¯å£
            model="qwen2:7b",  # ä½¿ç”¨å·²å®‰è£çš„ qwen2:7b æ¨¡å‹
            token_encoding="o200k_base",
        )
        print("ğŸ¤– ä½¿ç”¨æœ¬åœ° Ollama LLM (qwen2:7b)")
        return llm
    elif llm_type == "deepseek":
        # DeepSeek é›²ç«¯é…ç½®
        llm = LLM(
            key="sk-XXXXX",  # æ‚¨çš„ DeepSeek API key
            url="https://api.deepseek.com",
            model="deepseek-chat",
            token_encoding="o200k_base",
        )
        print("â˜ï¸ ä½¿ç”¨ DeepSeek é›²ç«¯ LLM")
        return llm
    else:
        print("âŒ æœªä½¿ç”¨ LLM æ ¡æ­£")
        return None

def process_math_formulas(text):
    """è™•ç†æ•¸å­¸å…¬å¼ï¼Œè½‰æ›ç‚ºLaTeXæ ¼å¼"""
    # è­˜åˆ¥å¸¸è¦‹çš„æ•¸å­¸ç¬¦è™Ÿå’Œè¡¨é”å¼
    math_patterns = [
        # åˆ†æ•¸
        (r'(\d+)/(\d+)', r'\\frac{\1}{\2}'),
        # å¹³æ–¹æ ¹
        (r'âˆš(\w+)', r'\\sqrt{\1}'),
        # æŒ‡æ•¸
        (r'(\w+)\^(\w+)', r'\1^{\2}'),
        # å¸Œè‡˜å­—æ¯
        (r'Î±', r'\\alpha'),
        (r'Î²', r'\\beta'),
        (r'Î³', r'\\gamma'),
        (r'Ï€', r'\\pi'),
        (r'Î¸', r'\\theta'),
        # æ•¸å­¸é‹ç®—ç¬¦
        (r'Â±', r'\\pm'),
        (r'â‰¤', r'\\leq'),
        (r'â‰¥', r'\\geq'),
        (r'â‰ ', r'\\neq'),
        (r'âˆ', r'\\infty'),
        # çµ•å°å€¼
        (r'\|([^|]+)\|', r'|\1|'),
        # è² è™Ÿ
        (r'ï¼', r'-'),  # å…¨å½¢è² è™Ÿè½‰åŠå½¢
        (r'â€”', r'-'),   # ç ´æŠ˜è™Ÿè½‰è² è™Ÿ
    ]
    
    processed_text = text
    for pattern, replacement in math_patterns:
        processed_text = re.sub(pattern, replacement, processed_text)
    
    return processed_text

def convert_pdf_to_markdown(pdf_path, output_dir, image_output_dir, extractor, llm=None, encoding="utf-8", 
                          enable_math_processing=True, enable_multilingual_ocr=True, use_llm_correction=False):
    """è½‰æ›å–®å€‹PDFæª”æ¡ˆç‚ºMarkdownï¼Œæ”¯æ´å¤šé‡OCRå’Œæ•¸å­¸å…¬å¼è™•ç†"""
    try:
        # å»ºç«‹è¼¸å‡ºç›®éŒ„
        output_dir.mkdir(parents=True, exist_ok=True)
        image_output_dir.mkdir(parents=True, exist_ok=True)
        
        # ç”Ÿæˆè¼¸å‡ºæª”æ¡ˆåç¨±
        pdf_name = pdf_path.stem
        output_md_path = output_dir / f"{pdf_name}.md"
        
        print(f"ğŸ”„ æ­£åœ¨è½‰æ›: {pdf_path.name}")
        print(f"   ğŸ“ æ•¸å­¸å…¬å¼è™•ç†: {'å•Ÿç”¨' if enable_math_processing else 'åœç”¨'}")
        print(f"   ğŸŒ å¤šèªè¨€OCR: {'å•Ÿç”¨' if enable_multilingual_ocr else 'åœç”¨'}")
        print(f"   ğŸ¤– LLMæ ¡æ­£: {'å•Ÿç”¨' if use_llm_correction and llm else 'åœç”¨'}")
        start_time = time.time()
        
        if use_llm_correction and llm:
            # ä½¿ç”¨ LLM é€²è¡Œ OCR æ ¡æ­£
            print("   ğŸ”§ ä½¿ç”¨ LLM é€²è¡Œ OCR æ ¡æ­£...")
            # é å…ˆå»ºç«‹ correction/output/text ç›®éŒ„ï¼Œé¿å…è·¯å¾‘ä¸å­˜åœ¨éŒ¯èª¤
            correction_text_dir = output_dir / "temp_analysing" / "correction" / "output" / "text"
            correction_text_dir.mkdir(parents=True, exist_ok=True)
            analyse(
                pdf_page_extractor=extractor,
                pdf_path=str(pdf_path),
                analysing_dir_path=str(output_dir / "temp_analysing"),
                output_dir_path=str(output_dir / "temp_output"),
                llm=llm,
                correction_mode=CorrectionMode.DETAILED,
            )
            # å¾æ ¡æ­£å¾Œçš„çµæœç”Ÿæˆ Markdown
            # é€™è£¡éœ€è¦æ ¹æ“š analyse çš„è¼¸å‡ºæ ¼å¼é€²è¡Œè™•ç†
            print("   âœ… LLM æ ¡æ­£å®Œæˆ")
        else:
            # ç›´æ¥è½‰æ›PDFç‚ºMarkdown
            with MarkDownWriter(output_md_path, image_output_dir, encoding) as md:
                for block in extractor.extract(str(pdf_path)):
                    if enable_math_processing and hasattr(block, 'text'):
                        block.text = process_math_formulas(block.text)
                    
                    # å¯«å…¥å€å¡Š
                    md.write(block)
        
        elapsed_time = time.time() - start_time
        print(f"âœ… å®Œæˆè½‰æ›: {pdf_name} (è€—æ™‚: {elapsed_time:.2f}ç§’)")
        print(f"   è¼¸å‡ºæª”æ¡ˆ: {output_md_path}")
        
        return True, output_md_path
        
    except Exception as e:
        print(f"âŒ è½‰æ›å¤±æ•—: {pdf_path.name} - {e}")
        return False, None

def process_subject(subject, base_input_dir, output_base_dir, image_output_dir, model_cache_path, 
                   device, encoding, enable_math_processing, enable_multilingual_ocr, extract_table_format,
                   llm_type="none", use_llm_correction=False):
    """è™•ç†å–®å€‹ç§‘ç›®çš„æ‰€æœ‰PDFæª”æ¡ˆ"""
    print(f"\n{'='*20} è™•ç† {subject} ç§‘ç›® {'='*20}")
    
    subject_dir = base_input_dir / subject
    if not subject_dir.exists():
        print(f"âŒ ç§‘ç›®ç›®éŒ„ä¸å­˜åœ¨: {subject_dir}")
        return subject, 0, 0
        
    subject_pdfs = list(subject_dir.glob("*.pdf"))
    if not subject_pdfs:
        print(f"âŒ æœªæ‰¾åˆ° {subject} ç§‘ç›®çš„PDFæª”æ¡ˆ")
        return subject, 0, 0
        
    print(f"ğŸ“š {subject}: æ‰¾åˆ° {len(subject_pdfs)} å€‹PDFæª”æ¡ˆ")
    
    # ç‚ºç§‘ç›®å»ºç«‹è¼¸å‡ºç›®éŒ„
    subject_output_dir = output_base_dir / subject
    subject_image_dir = image_output_dir / subject
    
    # è¨­å®š LLM
    llm = setup_llm(llm_type) if use_llm_correction else None
    
    # åˆå§‹åŒ–PDFè§£æå™¨ï¼ˆæ¯å€‹é€²ç¨‹ç¨ç«‹ï¼‰
    extractor = create_pdf_page_extractor(
        device=device,
        model_dir_path=str(model_cache_path),
        extract_formula=True,
        extract_table_format=extract_table_format,
    )
    
    if not extractor:
        print(f"âŒ {subject} PDFè§£æå™¨åˆå§‹åŒ–å¤±æ•—")
        return subject, 0, len(subject_pdfs)
    
    subject_successful = 0
    subject_failed = 0
    
    for i, pdf_path in enumerate(subject_pdfs, 1):
        print(f"\n[{i}/{len(subject_pdfs)}] è™•ç† {subject} æª”æ¡ˆ...")
        
        success, output_path = convert_pdf_to_markdown(
            pdf_path, 
            subject_output_dir, 
            subject_image_dir, 
            extractor, 
            llm,
            encoding,
            enable_math_processing=enable_math_processing,
            enable_multilingual_ocr=enable_multilingual_ocr,
            use_llm_correction=use_llm_correction
        )
        
        if success:
            subject_successful += 1
        else:
            subject_failed += 1
    
    # ç§‘ç›®å®Œæˆå ±å‘Š
    print(f"\nğŸ“Š {subject} ç§‘ç›®å®Œæˆå ±å‘Š:")
    print(f"   âœ… æˆåŠŸ: {subject_successful} å€‹æª”æ¡ˆ")
    print(f"   âŒ å¤±æ•—: {subject_failed} å€‹æª”æ¡ˆ")
    print(f"   ğŸ“ è¼¸å‡ºç›®éŒ„: {subject_output_dir}")
    
    return subject, subject_successful, subject_failed

def batch_convert_all_pdfs(root_dir, output_base_dir, image_output_dir, model_cache_path, device, encoding, enable_math_processing, enable_multilingual_ocr, extract_table_format):
    pdf_files = list(Path(root_dir).rglob("*.pdf"))
    print(f"\nğŸ” å…±æ‰¾åˆ° {len(pdf_files)} å€‹ PDF æª”æ¡ˆæ–¼ {root_dir}")
    # åˆå§‹åŒ–PDFè§£æå™¨ï¼ˆå…±ç”¨ï¼‰
    extractor = create_pdf_page_extractor(
        device=device,
        model_dir_path=str(model_cache_path),
        extract_formula=True,
        extract_table_format=extract_table_format,
    )
    success_count = 0
    fail_count = 0
    for i, pdf_path in enumerate(pdf_files, 1):
        # ä¾æ“š PDF æ‰€åœ¨ç›®éŒ„å»ºç«‹å°æ‡‰è¼¸å‡ºè³‡æ–™å¤¾
        rel_dir = pdf_path.parent.relative_to(root_dir)
        out_dir = output_base_dir / rel_dir
        img_dir = image_output_dir / rel_dir
        print(f"\n[{i}/{len(pdf_files)}] è™•ç† {pdf_path}")
        success, output_path = convert_pdf_to_markdown(
            pdf_path,
            out_dir,
            img_dir,
            extractor,
            llm=None,
            encoding=encoding,
            enable_math_processing=enable_math_processing,
            enable_multilingual_ocr=enable_multilingual_ocr,
            use_llm_correction=False
        )
        if success:
            success_count += 1
        else:
            fail_count += 1
    print(f"\nğŸ“Š éè¿´æ‰¹æ¬¡è½‰æ›å®Œæˆï¼šæˆåŠŸ {success_count}ï¼Œå¤±æ•— {fail_count}")

def main():
    # === è¨­å®šè·¯å¾‘ ===
    base_input_dir = Path("input_docs/111A/7/Hanlin")
    output_base_dir = Path("output_docs/test_batch")
    image_output_dir = Path("images/test_batch")
    model_cache_path = Path("model")
    # === è¨­å®šåƒæ•¸ ===
    device = "cpu"  # æˆ– "cuda"
    encoding = "utf-8"
    enable_math_processing = True
    enable_multilingual_ocr = True
    extract_table_format = ExtractedTableFormat.MARKDOWN
    # === éè¿´æ‰¹æ¬¡è™•ç†æ‰€æœ‰ PDF ===
    batch_convert_all_pdfs(
        base_input_dir,
        output_base_dir,
        image_output_dir,
        model_cache_path,
        device,
        encoding,
        enable_math_processing,
        enable_multilingual_ocr,
        extract_table_format
    )

if __name__ == "__main__":
    main()